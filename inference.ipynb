{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX7YPo1jTRjf",
        "outputId": "e3f487b2-790b-4ac1-f61d-1a837695e151"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3gJNppYTTDE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import gc\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModel, AutoTokenizer, AutoConfig, DataCollatorWithPadding, RobertaPreTrainedModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLXs4PnLTV1E",
        "outputId": "6026bf2e-b30b-4414-a95b-d10c8221ce46"
      },
      "outputs": [],
      "source": [
        "CONFIG = {\"seed\": 42,\n",
        "          \"epochs\": 3,\n",
        "          \"model_name\": \"huggingface/CodeBERTa-small-v1\",\n",
        "          \"train_bsize\": 16,\n",
        "          \"val_bsize\":64,\n",
        "          \"max_length\": 256,\n",
        "          \"learning_rate\": 0.004, \n",
        "          \"scheduler\": 'get_linear_schedule_with_warmup',\n",
        "          \"weight_decay\": 0.01,\n",
        "          \"n_fold\":2,\n",
        "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "          }\n",
        "\n",
        "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
        "print(CONFIG['device'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### test df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSH-ceY1TYtE",
        "outputId": "9594e13b-fed0-4790-eb83-42fb7ba69816"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(179700, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = pd.read_csv('./drive/MyDrive/data/test.csv')\n",
        "test_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### step function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkLrQF8gTfOk"
      },
      "outputs": [],
      "source": [
        "CONFIG['threshold'] = 0.5\n",
        "def step_function(value):\n",
        "    return (value.view(-1) >= torch.tensor(CONFIG['threshold']).to(CONFIG['device'])).int()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9UM0l5WTiFs"
      },
      "outputs": [],
      "source": [
        "def sub_tokenizing(dataset):\n",
        "    codes1 = dataset['code1'].tolist()\n",
        "    codes2 = dataset['code2'].tolist()\n",
        "    print(\"codes1, codes2 length:\", len(codes1), len(codes2))\n",
        "\n",
        "    tokenized = CONFIG['tokenizer'](\n",
        "        codes1,\n",
        "        return_tensors='pt',\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=CONFIG['max_length']\n",
        "    )\n",
        "    tokenized2 =  CONFIG['tokenizer'](\n",
        "        codes2,\n",
        "        return_tensors='pt',\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=CONFIG['max_length']\n",
        "    )\n",
        "    for key, value in tokenized2.items():\n",
        "        tokenized[key+\"2\"] = value\n",
        "\n",
        "    return tokenized, len(codes1)\n",
        "\n",
        "\n",
        "# Dataset 구성.\n",
        "class SubCustomDataset(Dataset):\n",
        "    def __init__(self, tokenized_dataset, length):\n",
        "        self.tokenized_dataset = tokenized_dataset\n",
        "        self.length = length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.tokenized_dataset.items()}\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    \n",
        "def sub_pro_dataset(dataset):\n",
        "    tokenized, length = sub_tokenizing(dataset)\n",
        "    custom_dataset = SubCustomDataset(tokenized, length)\n",
        "    print(\"Custom dataset size:\", len(custom_dataset))\n",
        "    dataloader = DataLoader(\n",
        "        custom_dataset, \n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "        batch_size=CONFIG['val_bsize']\n",
        "    )\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-vBQVlbTx5D",
        "outputId": "e263cdef-f3bc-480e-bd72-0d7b57a05c0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "codes1, codes2 length: 179700 179700\n",
            "Custom dataset size: 179700\n"
          ]
        }
      ],
      "source": [
        "test_dataloader = sub_pro_dataset(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOXm2JlZUTTc"
      },
      "outputs": [],
      "source": [
        "# Customized model \n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.model = AutoModel.from_pretrained(CONFIG['model_name'], config=config)\n",
        "        self.similarity_fn = nn.CosineSimilarity()\n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Linear(1, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "        gc.collect()\n",
        "    def forward(self, input_ids=None, attention_mask=None, \n",
        "                input_ids2=None, attention_mask2=None, labels=None):\n",
        "        gc.collect()\n",
        "        outputs1 = self.model(\n",
        "            input_ids, attention_mask=attention_mask\n",
        "        )\n",
        "        gc.collect()\n",
        "        outputs2 = self.model(\n",
        "            input_ids2, attention_mask=attention_mask2\n",
        "        )\n",
        "        gc.collect()\n",
        "        pooler1 = outputs1[0]\n",
        "        pooler2 = outputs2[0]\n",
        "\n",
        "        # Mean\n",
        "        pooler1 =  pooler1.mean(dim=1) # self.pooling(pooler1, attention_mask)\n",
        "        pooler2 =  pooler2.mean(dim=1) # self.pooling(pooler2, attention_mask2)\n",
        "\n",
        "        # Normalize\n",
        "        a_norm = F.normalize(pooler1, p=2, dim=1)\n",
        "        b_norm = F.normalize(pooler2, p=2, dim=1)\n",
        "\n",
        "        sim_score =  self.similarity_fn(a_norm, b_norm)\n",
        "        sim_score = sim_score.unsqueeze(-1)\n",
        "        sim_score = self.sequential(sim_score)\n",
        "        del pooler1, pooler2, a_norm, b_norm\n",
        "\n",
        "        return sim_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lWX7xaZaAIG",
        "outputId": "e7754037-d11a-41b0-ff01-e3b9771c434d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gc.collect()\n",
        "gc.collect()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rRpSDrBZDNw",
        "outputId": "ac36c270-5440-4f85-dc75-dd007359a0e1"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = ['/content/drive/MyDrive//Loss-Fold-0.pt',\n",
        "              '/content/drive/MyDrive//Loss-Fold-1.pt',\n",
        "             ]\n",
        "MODEL_CONFIG = AutoConfig.from_pretrained(CONFIG['model_name'])\n",
        "model = CustomModel(MODEL_CONFIG).to(CONFIG['device'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNiQIlR_Zb4v",
        "outputId": "4fccb7a8-940a-4425-8716-49a9af82b25a"
      },
      "outputs": [],
      "source": [
        "# 예측값 저장 리스트\n",
        "preds_lst = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, path in enumerate(MODEL_PATH):\n",
        "    print(f'===getting predictions for model {i+1}===')\n",
        "\n",
        "    model.load_state_dict(torch.load(path, map_location=CONFIG['device']))\n",
        "    model.eval()\n",
        "\n",
        "    preds = []\n",
        "\n",
        "    bar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
        "    for idx, items in bar:\n",
        "      sleep(0.1)\n",
        "\n",
        "      item = {key: val.to(CONFIG['device']) for key,val in items.items()}\n",
        "      outputs = model(**item)\n",
        "\n",
        "      preds.append(outputs)\n",
        "    preds_lst.append(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgePXgUXVWuz"
      },
      "outputs": [],
      "source": [
        "a = preds_lst\n",
        "b = []\n",
        "b.append([((a[0][i]+a[1][i])/2) for i in range(len(a[0]))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_-I6IOGVzrF"
      },
      "outputs": [],
      "source": [
        "c = []\n",
        "c.append([np.argmax(b[0][i].cpu() > 0.5, axis=-1) for i in range(len(b[0]))])\n",
        "c_lst = [c[0][i].tolist() for i in range(len(c[0]))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMLof9A0WxYj"
      },
      "outputs": [],
      "source": [
        "final_preds = sum(c_lst, [])\n",
        "len(final_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqiIE7XPJgNG"
      },
      "outputs": [],
      "source": [
        "sub_f = pd.read_csv('./drive/MyDrive/data/sample_submission.csv')\n",
        "sub_f['similar'] = final_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COxnUTxSWmgf"
      },
      "outputs": [],
      "source": [
        "## 예측 결과 저장\n",
        "sub_f.to_csv('./drive/MyDrive/data/subff.csv', index = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
